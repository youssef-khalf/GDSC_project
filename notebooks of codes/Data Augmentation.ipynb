{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a small dataset, I used data augmentation in order to create more images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we could solve the data imbalance issue (since 61% of the data belongs to the tumorous class) using data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import time    \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation Function\n",
    "\n",
    "### Inputs:\n",
    "- **file_dir**: Directory containing the original images to be augmented.\n",
    "- **n_generated_samples**: Number of augmented samples to generate for each original image.\n",
    "- **save_to_dir**: Directory to save the generated augmented images.\n",
    "\n",
    "### Data Augmentation Techniques:\n",
    "- Rotation by a maximum of 10 degrees.\n",
    "- Horizontal and vertical shifts by a maximum of 10% of the image dimensions.\n",
    "- Shear transformation with a maximum shear of 0.1.\n",
    "- Brightness adjustment within the range of 0.3 to 1.0.\n",
    "- Horizontal and vertical flips.\n",
    "- Nearest-neighbor filling mode for pixels outside the boundaries.\n",
    "\n",
    "### Processing:\n",
    "- Iterates through each file in the specified directory.\n",
    "- Loads the original image using OpenCV.\n",
    "- Reshapes the image and sets a prefix for the generated samples.\n",
    "- Uses an image data generator to apply random transformations to generate augmented samples.\n",
    "- Saves the augmented samples with prefixed filenames in the specified output directory.\n",
    "\n",
    "### Output:\n",
    "- Augmented images saved in the specified directory for each original image.\n",
    "###   generate 5 augmented samples for each original image..\n",
    "\n",
    "In essence, this function is a convenient way to create additional training data by applying various transformations to the original images, which can help improve the robustness and generalization of a machine learning model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(file_dir, n_generated_samples, save_to_dir):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        file_dir: A string representing the directory where images that we want to augment are found.\n",
    "        n_generated_samples: A string representing the number of generated samples using the given image.\n",
    "        save_to_dir: A string representing the directory in which the generated images will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    #from keras.preprocessing.image import ImageDataGenerator\n",
    "    #from os import listdir\n",
    "    \n",
    "    data_gen = ImageDataGenerator(rotation_range=10, \n",
    "                                  width_shift_range=0.1, \n",
    "                                  height_shift_range=0.1, \n",
    "                                  shear_range=0.1, \n",
    "                                  brightness_range=(0.3, 1.0),\n",
    "                                  horizontal_flip=True, \n",
    "                                  vertical_flip=True, \n",
    "                                  fill_mode='nearest'\n",
    "                                 )\n",
    "\n",
    "    \n",
    "    for filename in listdir(file_dir):\n",
    "        # load the image\n",
    "        image = cv2.imread(file_dir + '\\\\' + filename)\n",
    "        # reshape the image\n",
    "        image = image.reshape((1,)+image.shape)\n",
    "        # prefix of the names for the generated sampels.\n",
    "        save_prefix = 'aug_' + filename[:-4]\n",
    "        # generate 'n_generated_samples' sample images\n",
    "        i=0\n",
    "        for batch in data_gen.flow(x=image, batch_size=1, save_to_dir=save_to_dir, \n",
    "                                           save_prefix=save_prefix, save_format='jpg'):\n",
    "            i += 1\n",
    "            if i > n_generated_samples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that 61% of the data (155 images) are tumorous. And, 39% of the data (98 images) are non-tumorous.<br>\n",
    "So, in order to balance the data we can generate 9 new images for every image that belongs to 'no' class and 6 images for every image that belongs the 'yes' class.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:34:1.5\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# augment data for the examples with label equal to 'yes' representing tumurous examples\n",
    "augment_data(file_dir=\"C:/Users/lenovo/Desktop/Siar-dataset/Tumor\", n_generated_samples=6, save_to_dir=\"C:/Users/lenovo/Desktop/Siar-dataset/yes\")\n",
    "# augment data for the examples with label equal to 'no' representing non-tumurous examples\n",
    "augment_data(file_dir=\"C:/Users/lenovo/Desktop/Siar-dataset/Normal\", n_generated_samples=9, save_to_dir=\"C:/Users/lenovo/Desktop/Siar-dataset/no\")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many tumorous and non-tumorous examples after performing data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_summary(main_path):\n",
    "    \n",
    "    yes_path = main_path+'yes'\n",
    "    no_path = main_path+'no'\n",
    "        \n",
    "    # number of files (images) that are in the the folder named 'yes' that represent tumorous (positive) examples\n",
    "    m_pos = len(listdir(yes_path))\n",
    "    # number of files (images) that are in the the folder named 'no' that represent non-tumorous (negative) examples\n",
    "    m_neg = len(listdir(no_path))\n",
    "    # number of all examples\n",
    "    m = (m_pos+m_neg)\n",
    "    \n",
    "    pos_prec = (m_pos* 100.0)/ m\n",
    "    neg_prec = (m_neg* 100.0)/ m\n",
    "    \n",
    "    print(f\"Number of examples: {m}\")\n",
    "    print(f\"Percentage of positive examples: {pos_prec}%, number of pos examples: {m_pos}\") \n",
    "    print(f\"Percentage of negative examples: {neg_prec}%, number of neg examples: {m_neg}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data_path=\"C:/Users/lenovo/Desktop/Siar-dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 60361\n",
      "Percentage of positive examples: 37.08851742018853%, number of pos examples: 22387\n",
      "Percentage of negative examples: 62.91148257981147%, number of neg examples: 37974\n"
     ]
    }
   ],
   "source": [
    "data_summary(augmented_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for this notebook. Now, we can use the augmented data to train our convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
